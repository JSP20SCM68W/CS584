{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from decimal import Decimal\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from decimal import Decimal\n",
    "from scipy.misc import comb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename,delimiter=',')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_spamdata(data,x_index):\n",
    "#     print 'preprocessing data'\n",
    "    x = data[:,:x_index+1]\n",
    "    y = data[:,-1]\n",
    "    X = []\n",
    "    for i in x:\n",
    "        temp = []\n",
    "        for feature in i:\n",
    "            if feature>0:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        X.append(temp)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indicator(Y,class_val):\n",
    "    l = list()\n",
    "    for idx,y in enumerate(Y):\n",
    "        if y == class_val:\n",
    "            l.append(idx)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_prior(Y,class_val):\n",
    "    m = len(Y)\n",
    "    indices = indicator(Y,class_val)\n",
    "    return (1.*len(indices)/m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with Bernoulli featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' all the alphai values of all the features of a specific x'''\n",
    "def compute_alphai(X,indices,E=0.01):\n",
    "    alpha = dict()\n",
    "    for col in range(X.shape[1]):\n",
    "        feat_col = X[:,col]\n",
    "        a = 1.*(sum(feat_col[indices]) + E)/len(indices)+(2*E)\n",
    "        alpha[col] = a\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def membership_fun_ber(x,Y,class_val,alphai,priori):\n",
    "    s = 0\n",
    "    for ind,i in enumerate(x):\n",
    "        a = alphai[ind]\n",
    "        s += i*(math.log(a)) + (1-i)*(math.log(1-a))\n",
    "    return (s+math.log(priori))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_NBBer(filename,k):\n",
    "    \n",
    "    data = load_data(filename)\n",
    "    X,Y = preprocess_spamdata(data,48)\n",
    "    accuracy = list()\n",
    "    precision = list()\n",
    "    recall = list()\n",
    "    f_measure = list()\n",
    "    fold = 1\n",
    "    for train_ind, test_ind in KFold(X.shape[0],k,shuffle=True,random_state=5):\n",
    "        X_train = np.array(X)[train_ind]\n",
    "        Y_train = np.array(Y)[train_ind]\n",
    "        X_test = np.array(X)[test_ind]\n",
    "        Y_test = np.array(Y)[test_ind]\n",
    "        Y_predict = NB_Bern_exp(X_train,Y_train,X_test)\n",
    "        \n",
    "        temp = accuracy_score(Y_test,Y_predict,normalize=True, sample_weight=None)\n",
    "        c_matrix = confusion_matrix(Y_test, Y_predict)\n",
    "        prec = precision_score(Y_test, Y_predict) \n",
    "        rec = recall_score(Y_test, Y_predict)  \n",
    "        fm = f1_score(Y_test, Y_predict)\n",
    "    \n",
    "        accuracy.append(temp)\n",
    "        recall.append(rec)\n",
    "        precision.append(prec)\n",
    "        f_measure.append(fm)\n",
    "        \n",
    "        print 'fold:', fold\n",
    "        print 'accuracy:', temp\n",
    "        print 'confusion_matrix', c_matrix\n",
    "        print 'prediction', prec\n",
    "        print 'recall' , rec\n",
    "        fold += 1\n",
    "    \n",
    "    avg_acc = sum(accuracy)/len(accuracy)\n",
    "    avg_pre = sum(precision)/len(precision)\n",
    "    avg_rec = sum(recall)/len(recall)\n",
    "    avg_fm = sum(f_measure)/len(f_measure)\n",
    "   \n",
    "    print 'avg_accuracy: ' , avg_acc\n",
    "    print 'avg_precision', avg_pre\n",
    "    print 'avg_recall', avg_rec\n",
    "    print 'avg_fmeasure', avg_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "accuracy: 0.872017353579\n",
      "confusion_matrix [[269  14]\n",
      " [ 45 133]]\n",
      "prediction 0.904761904762\n",
      "recall 0.747191011236\n",
      "fold: 2\n",
      "accuracy: 0.882608695652\n",
      "confusion_matrix [[269  23]\n",
      " [ 31 137]]\n",
      "prediction 0.85625\n",
      "recall 0.815476190476\n",
      "fold: 3\n",
      "accuracy: 0.863043478261\n",
      "confusion_matrix [[250  27]\n",
      " [ 36 147]]\n",
      "prediction 0.844827586207\n",
      "recall 0.803278688525\n",
      "fold: 4\n",
      "accuracy: 0.845652173913\n",
      "confusion_matrix [[254  20]\n",
      " [ 51 135]]\n",
      "prediction 0.870967741935\n",
      "recall 0.725806451613\n",
      "fold: 5\n",
      "accuracy: 0.854347826087\n",
      "confusion_matrix [[254  13]\n",
      " [ 54 139]]\n",
      "prediction 0.914473684211\n",
      "recall 0.720207253886\n",
      "fold: 6\n",
      "accuracy: 0.902173913043\n",
      "confusion_matrix [[262  13]\n",
      " [ 32 153]]\n",
      "prediction 0.921686746988\n",
      "recall 0.827027027027\n",
      "fold: 7\n",
      "accuracy: 0.910869565217\n",
      "confusion_matrix [[256  11]\n",
      " [ 30 163]]\n",
      "prediction 0.936781609195\n",
      "recall 0.844559585492\n",
      "fold: 8\n",
      "accuracy: 0.84347826087\n",
      "confusion_matrix [[253  20]\n",
      " [ 52 135]]\n",
      "prediction 0.870967741935\n",
      "recall 0.72192513369\n",
      "fold: 9\n",
      "accuracy: 0.871739130435\n",
      "confusion_matrix [[282  26]\n",
      " [ 33 119]]\n",
      "prediction 0.820689655172\n",
      "recall 0.782894736842\n",
      "fold: 10\n",
      "accuracy: 0.858695652174\n",
      "confusion_matrix [[243  29]\n",
      " [ 36 152]]\n",
      "prediction 0.839779005525\n",
      "recall 0.808510638298\n",
      "avg_accuracy:  0.870462604923\n",
      "avg_precision 0.878118567593\n",
      "avg_recall 0.779687671708\n",
      "avg_fmeasure 0.824968973622\n"
     ]
    }
   ],
   "source": [
    "cross_validation_NBBer('spambase.data.txt',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#    Naive Bayes with Binomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_spamdata_bi(data,x_index):\n",
    "#     print 'preprocessing data'\n",
    "    x = data[:,:x_index+1]\n",
    "    y = data[:,-1]\n",
    "    X = []\n",
    "    for i in x:\n",
    "        temp = []\n",
    "        for feature in i:\n",
    "            temp.append(feature*20)\n",
    "        X.append(temp)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(y)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_length(X):\n",
    "    doc_lengths = dict()\n",
    "    for index,x in enumerate(X):\n",
    "        doc_lengths[index] = sum(x)\n",
    "    return doc_lengths\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''computing the alphaj for all the columns/features for a given label '''\n",
    "def compute_alphai_Bi(indices,X,doc_length,E=0.01,k=2):\n",
    "    alphaj = dict()\n",
    "    n = 0\n",
    "    d = sum([doc_length[i] for i in indices])\n",
    "    for col in range(X.shape[1]):\n",
    "        column = X[:,col]\n",
    "        n = sum(column[indices])\n",
    "        alphaj[col] = 1.*(n+E)/(d+(k*E))\n",
    "    return alphaj\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def membership_Bi(alphaj,prior,x):\n",
    "    s = 0\n",
    "    doc_len = sum(x)+10\n",
    "    f = math.factorial\n",
    "    for j in range(x.size):\n",
    "        c = 1.*comb(doc_len,x[j])\n",
    "        a = (alphaj[j])**(x[j])\n",
    "        b = (1 - alphaj[j])**(doc_len-(x[j]))\n",
    "        if (a*b) != 0:\n",
    "            s += (math.log(c*a*b))\n",
    "    r = (s + math.log(prior))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def t():\n",
    "    data = load_data('spambase.data.txt')\n",
    "    X,Y = preprocess_spamdata_bi(data,47)\n",
    "    print X.shape\n",
    "    doc_lengths = doc_length(X)\n",
    "   \n",
    "    prediction = list()\n",
    "    labels = np.unique(Y)\n",
    "    alphaj = dict()\n",
    "    prior = dict()\n",
    "    indices = dict()\n",
    "    \n",
    "    for label in labels:\n",
    "        indices[label] = indicator(Y,label)\n",
    "        prior[label] = compute_prior(Y,label)\n",
    "        alphaj[label] = compute_alphai_Bi(indices[label],X,doc_lengths)\n",
    "\n",
    "    for ind,x in enumerate(X[:10]):\n",
    "        temp = []\n",
    "        for label in labels:\n",
    "            m = membership_Bi(alphaj[label],prior[label],x)\n",
    "            temp.append(m)\n",
    "            print label,m\n",
    "        pred = labels[temp.index(max(temp))]\n",
    "        print 'pred', pred\n",
    "        print ' '\n",
    "        prediction.append(pred)\n",
    "    \n",
    "    print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 48)\n",
      "0.0 -974.365588521\n",
      "1.0 -490.336427648\n",
      "pred 1.0\n",
      " \n",
      "0.0 -1339.71699562\n",
      "1.0 -370.762775278\n",
      "pred 1.0\n",
      " \n",
      "0.0 -1325.25304991\n",
      "1.0 -567.583764484\n",
      "pred 1.0\n",
      " \n",
      "0.0 -1218.35768732\n",
      "1.0 -490.936192987\n",
      "pred 1.0\n",
      " \n",
      "0.0 -1218.35768732\n",
      "1.0 -490.936192987\n",
      "pred 1.0\n",
      " \n",
      "0.0 -858.044931566\n",
      "1.0 -1107.54760191\n",
      "pred 0.0\n",
      " \n",
      "0.0 -1259.92664965\n",
      "1.0 -729.800942115\n",
      "pred 1.0\n",
      " \n",
      "0.0 -408.080528831\n",
      "1.0 -1125.53460989\n",
      "pred 0.0\n",
      " \n",
      "0.0 -1499.15453533\n",
      "1.0 -707.849930676\n",
      "pred 1.0\n",
      " \n",
      "0.0 -869.52024538\n",
      "1.0 -307.658539848\n",
      "pred 1.0\n",
      " \n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NB_Bino_exp(X,Y,x_predict):\n",
    "    indices = dict()\n",
    "    class_prior = dict()\n",
    "    prediction = list()\n",
    "    alphaj = dict()\n",
    "    labels = np.unique(Y)\n",
    "    doc_lengths = doc_length(X)\n",
    "    \n",
    "    for label in labels:\n",
    "        indices[label] = indicator(Y,label)\n",
    "        class_prior[label] = compute_prior(Y,label)\n",
    "        alphaj[label] = compute_alphai_Bi(indices[label],X,doc_lengths)\n",
    "    \n",
    "    for ind,x in enumerate(x_predict):\n",
    "        temp = []\n",
    "        for label in labels:\n",
    "            temp.append(membership_Bi(alphaj[label],class_prior[label],x))\n",
    "        pred = labels[temp.index(max(temp))]\n",
    "        prediction.append(pred)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_NBBi(filename,k):\n",
    "    \n",
    "    data = load_data(filename)\n",
    "    X,Y = preprocess_spamdata_bi(data,47)\n",
    "#     X,Y = preprocess_spamdata(data,47)\n",
    "    accuracy = list()\n",
    "    precision = list()\n",
    "    recall = list()\n",
    "    f_measure = list()\n",
    "    fold = 1\n",
    "    for train_ind, test_ind in KFold(X.shape[0],k,shuffle=True,random_state=5):\n",
    "        X_train = np.array(X)[train_ind]\n",
    "        Y_train = np.array(Y)[train_ind]\n",
    "        X_test = np.array(X)[test_ind]\n",
    "        Y_test = np.array(Y)[test_ind]\n",
    "        Y_predict = NB_Bino_exp(X_train,Y_train,X_test)\n",
    "        \n",
    "        temp = accuracy_score(Y_test,Y_predict,normalize=True, sample_weight=None)\n",
    "        c_matrix = confusion_matrix(Y_test, Y_predict)\n",
    "        prec = precision_score(Y_test, Y_predict) \n",
    "        rec = recall_score(Y_test, Y_predict)  \n",
    "        fm = f1_score(Y_test, Y_predict)\n",
    "    \n",
    "        accuracy.append(temp)\n",
    "        recall.append(rec)\n",
    "        precision.append(prec)\n",
    "        f_measure.append(fm)\n",
    "        \n",
    "        print 'fold:', fold\n",
    "        print 'accuracy:', temp\n",
    "        print 'confusion_matrix', c_matrix\n",
    "        print 'prediction', prec\n",
    "        print 'recall' , rec\n",
    "        fold += 1\n",
    "    \n",
    "    avg_acc = sum(accuracy)/len(accuracy)\n",
    "    avg_pre = sum(precision)/len(precision)\n",
    "    avg_rec = sum(recall)/len(recall)\n",
    "    avg_fm = sum(f_measure)/len(f_measure)\n",
    "   \n",
    "    print 'avg_accuracy: ' , avg_acc\n",
    "    print 'avg_precision', avg_pre\n",
    "    print 'avg_recall', avg_rec\n",
    "    print 'avg_fmeasure', avg_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "accuracy: 0.826464208243\n",
      "confusion_matrix [[214  69]\n",
      " [ 11 167]]\n",
      "prediction 0.707627118644\n",
      "recall 0.938202247191\n",
      "fold: 2\n",
      "accuracy: 0.826086956522\n",
      "confusion_matrix [[220  72]\n",
      " [  8 160]]\n",
      "prediction 0.689655172414\n",
      "recall 0.952380952381\n",
      "fold: 3\n",
      "accuracy: 0.802173913043\n",
      "confusion_matrix [[204  73]\n",
      " [ 18 165]]\n",
      "prediction 0.693277310924\n",
      "recall 0.901639344262\n",
      "fold: 4\n",
      "accuracy: 0.817391304348\n",
      "confusion_matrix [[205  69]\n",
      " [ 15 171]]\n",
      "prediction 0.7125\n",
      "recall 0.91935483871\n",
      "fold: 5\n",
      "accuracy: 0.826086956522\n",
      "confusion_matrix [[201  66]\n",
      " [ 14 179]]\n",
      "prediction 0.730612244898\n",
      "recall 0.927461139896\n",
      "fold: 6\n",
      "accuracy: 0.873913043478\n",
      "confusion_matrix [[226  49]\n",
      " [  9 176]]\n",
      "prediction 0.782222222222\n",
      "recall 0.951351351351\n",
      "fold: 7\n",
      "accuracy: 0.830434782609\n",
      "confusion_matrix [[205  62]\n",
      " [ 16 177]]\n",
      "prediction 0.740585774059\n",
      "recall 0.917098445596\n",
      "fold: 8\n",
      "accuracy: 0.839130434783\n",
      "confusion_matrix [[214  59]\n",
      " [ 15 172]]\n",
      "prediction 0.744588744589\n",
      "recall 0.919786096257\n",
      "fold: 9\n",
      "accuracy: 0.795652173913\n",
      "confusion_matrix [[225  83]\n",
      " [ 11 141]]\n",
      "prediction 0.629464285714\n",
      "recall 0.927631578947\n",
      "fold: 10\n",
      "accuracy: 0.817391304348\n",
      "confusion_matrix [[202  70]\n",
      " [ 14 174]]\n",
      "prediction 0.713114754098\n",
      "recall 0.925531914894\n",
      "avg_accuracy:  0.825472507781\n",
      "avg_precision 0.714364762756\n",
      "avg_recall 0.928043790949\n",
      "avg_fmeasure 0.806728285815\n"
     ]
    }
   ],
   "source": [
    "cross_validation_NBBi('spambase.data.txt',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
